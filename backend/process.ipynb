{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import hashlib, binascii\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n",
    "from os import listdir\n",
    "import re\n",
    "\n",
    "import plaid\n",
    "import sys\n",
    "sys.path.insert(1, '../private')\n",
    "import keys as keys\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFiles():\n",
    "    dlFiles = listdir(\"./download\")\n",
    "    try:\n",
    "        dlFiles.remove('.DS_Store')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    result = []\n",
    "    for file in dlFiles:\n",
    "        fileObject={\"name\":None, \"data\":None}\n",
    "        newData = pd.read_csv(\"./download/\"+file, header=None, names=newColumns)\n",
    "        fileObject[\"name\"] = file.split(\".\")[0]\n",
    "        fileObject[\"data\"] = newData\n",
    "        result.append(fileObject)\n",
    "    return result\n",
    "\n",
    "\n",
    "def getFile(file):\n",
    "    if file == \"data\":\n",
    "        return pd.read_csv(\"./data/data.csv\", header=None, names=oldColumns,index_col=False)\n",
    "    elif file == \"processed\":\n",
    "        return pd.read_csv(\"./data/processed.csv\",index_col=False)\n",
    "    elif file == \"maps\":\n",
    "        return pd.read_csv(\"./data/1to1maps.csv\", header=None, names=['item', 'subCategory'])\n",
    "    elif file == \"subCategories\":\n",
    "        return pd.read_csv(\"./data/categories.csv\", header=None, names=['item', 'subCategory'])\n",
    "    elif file == \"categories\":\n",
    "        return pd.read_csv(\"./data/breakdown.csv\", header=None, names=['subCategory', 'category'])\n",
    "    \n",
    "def writeFile(file, df):\n",
    "    if file ==\"maps\":\n",
    "        df.to_csv('./data/1to1maps.csv', index=False, header=False)  \n",
    "    elif file==\"subCategories\":\n",
    "        df.to_csv('./data/categories.csv', index=False, header=False)  \n",
    "    elif file ==\"data\":\n",
    "        df.to_csv('./data/data.csv', index=False, header=False)  \n",
    "\n",
    "        \n",
    "\n",
    "def saveDf(df, fileName, path, header = False):\n",
    "    miliTime = int(round(time.time()))\n",
    "    readableTime = datetime.utcfromtimestamp(miliTime).strftime('%Y-%m-%d')\n",
    "    df.to_csv(f'./backup/{fileName}-{readableTime}.csv', index=False, header=header)\n",
    "    df.to_csv(f'./{path}/{fileName}.csv', index=False, header=header)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hash Data\n",
    "\n",
    "oldColumns=['date','item','debit','credit','subCategory','hash', 'account']\n",
    "addedColumns = ['date','item','debit','credit','hash','account']\n",
    "newColumns=['date','item','debit','credit','card']\n",
    "processedColumns=['item','category','subCategory','date','year','month','debit','credit','balance', 'account']\n",
    "\n",
    "def hashit(df):\n",
    "    hashs = []\n",
    "    for index, row in df.iterrows():\n",
    "        h = hashlib.new('ripemd160')\n",
    "        it = str(row['item'])\n",
    "        it2= ' '.join(re.findall(r\"[\\w']+\", it))\n",
    "        h.update(it2.encode())\n",
    "        h.update(str(row['credit']).encode())\n",
    "        h.update(str(row['debit']).encode())\n",
    "        h.update(str(row['date']).encode())\n",
    "        hashed =h.hexdigest()\n",
    "        hashs.append(hashed)\n",
    "    return hashs\n",
    "\n",
    "def testDf(df):\n",
    "    assert df.dtypes['debit'] == 'float64'\n",
    "    assert df.dtypes['credit'] == 'float64'\n",
    "\n",
    "def fixDf(df):\n",
    "    global oldColumns\n",
    "    df['subCategory'].fillna(\"\",inplace=True)\n",
    "    df=df[oldColumns]\n",
    "    return df\n",
    "\n",
    "def findNewItems(old, new, fileName):\n",
    "    new['hash']= hashit(new)\n",
    "    hashfound = []\n",
    "    for index, row in new.iterrows():\n",
    "        hashfound.append(row['hash'] in old['hash'].values)\n",
    "    new['hashfound']=hashfound\n",
    "    \n",
    "#     new.loc[new['hashfound'] == False, 'account'] = fileName;\n",
    "    new['account'] = new['card']\n",
    "    new.loc[new['card']==0, 'account']=fileName;\n",
    "    new.loc[new['card']==None, 'account']=fileName;\n",
    "\n",
    "    newItems = new[new['hashfound'] == False]\n",
    "    print(newItems)\n",
    "    return newItems\n",
    "\n",
    "def convertToJsonArray(df):\n",
    "    columns = df.columns\n",
    "    result = []\n",
    "    for i, row in df.iterrows():\n",
    "        dummy = {}\n",
    "        for column in columns:\n",
    "            dummy[column]=row[column]\n",
    "        result.append(dummy)\n",
    "    return(result)\n",
    "\n",
    "\n",
    "def writeToJson(df):\n",
    "    items = convertToJsonArray(df)\n",
    "    with open('data/data.json', 'w') as jsonFile:\n",
    "        json.dump(items, jsonFile)\n",
    "\n",
    "def listNewItems(files):\n",
    "    global oldColumns\n",
    "    old = getFile('data')\n",
    "    old['subCategory'].fillna(\"\",inplace=True)\n",
    "    old.fillna(value=0,inplace=True)\n",
    "    testDf(old)\n",
    "\n",
    "    combinedAll = old[oldColumns]\n",
    "    combinedNew = pd.DataFrame(columns=oldColumns)\n",
    "\n",
    "    for new in files:\n",
    "        newData = new['data']\n",
    "        newName = new['name']\n",
    "        newData.fillna(value=0,inplace=True)\n",
    "        testDf(newData)\n",
    "\n",
    "        newItems = findNewItems(combinedAll, newData, newName)\n",
    "        newToSave = newItems[addedColumns]\n",
    "\n",
    "        print(f\"{newName} - {len(newToSave)} new items found\")\n",
    "\n",
    "        combinedAll = pd.concat([combinedAll, newToSave])\n",
    "        combinedNew = pd.concat([combinedNew, newToSave])\n",
    "        \n",
    "    combinedNew = fixDf(combinedNew)\n",
    "    return combinedNew\n",
    "\n",
    "# Process Hashed Data\n",
    "def processData(newItems,doAll = False):\n",
    "    if doAll:\n",
    "        data = getFile('data')\n",
    "    else:\n",
    "        newItems.reset_index(inplace=True)\n",
    "        data = newItems.copy()\n",
    "\n",
    "    maps = getFile('maps')\n",
    "    subCategories = getFile('subCategories')\n",
    "    categories = getFile('categories')\n",
    "\n",
    "    categoryMap ={}\n",
    "    for i, row in categories.iterrows():\n",
    "        categoryMap[row['subCategory']] = row['category']\n",
    "\n",
    "    data.fillna(\"\", inplace=True)\n",
    "\n",
    "    subCatArray = []\n",
    "    # first mapping the 1to1 mappings\n",
    "    for i, row in data.iterrows():\n",
    "        if (row['subCategory'] != \"\"):\n",
    "            subCatArray.append(row['subCategory'])\n",
    "        else:\n",
    "            try:\n",
    "                index = pd.Index(maps['item']).get_loc(row['item'].rstrip())\n",
    "                subCategory = maps.loc[index]['subCategory']\n",
    "                subCatArray.append(subCategory)\n",
    "            except:\n",
    "                subCatArray.append(\"\")\n",
    "\n",
    "    # then mapping all the general categories\n",
    "    data['subCategory'] = subCatArray\n",
    "    subCatArray = pd.Series(subCatArray) \n",
    "\n",
    "\n",
    "    for i, categoryRow in subCategories.iloc[::-1].iterrows():\n",
    "        indo = ((data['item'].str.contains(categoryRow['item'])) & (data['subCategory']==\"\"))\n",
    "        subCatArray[indo] = categoryRow['subCategory']\n",
    "\n",
    "    data['balance']=data['credit']-data['debit']\n",
    "\n",
    "    # finally taking care of special categories with logic\n",
    "    specialCategories = subCategories[subCategories['item'].str.contains('{{')]\n",
    "    for i, categoryRow in specialCategories.iterrows():\n",
    "        itemValuePair = categoryRow['item'].replace('}}', '').split('{{')\n",
    "        indo = (data['item'].str.contains(itemValuePair[0].rstrip()) & (data['balance']==(float(itemValuePair[1]))))\n",
    "        subCatArray[indo] = categoryRow['subCategory']\n",
    "\n",
    "    data['subCategory'] = subCatArray\n",
    "    data['category'] = data['subCategory'].map(categoryMap)\n",
    "    data['year']= pd.to_datetime(data['date']).dt.year\n",
    "    data['month']= pd.to_datetime(data['date']).dt.month    \n",
    "    return data\n",
    "\n",
    "def runProcess(files):\n",
    "    newItems = listNewItems(files)\n",
    "    if(newItems['item'].count() > 0):\n",
    "        processedData = processData(newItems)   \n",
    "        dataWithoutCategory = (processedData[processedData['subCategory'] == \"\"])\n",
    "        if(len(dataWithoutCategory) == 0):\n",
    "            processedAlready = getFile('processed')\n",
    "            processedAll = pd.concat([processedData, processedAlready])\n",
    "            processedToSave = processedAll[processedColumns].sort_values(by='date', ascending=False)\n",
    "            saveDf(processedToSave, 'processed', 'data', True)\n",
    "\n",
    "            dataAll = getFile('data')\n",
    "            combinedData = pd.concat([dataAll, newItems])\n",
    "            combinedData = combinedData[oldColumns]\n",
    "            saveDf(combinedData, 'data', 'data', False)\n",
    "\n",
    "            writeToJson(processedToSave)\n",
    "\n",
    "            print(\"SAVED\")\n",
    "        else:\n",
    "            print('Found Gaps, NOT SAVED')\n",
    "            print(dataWithoutCategory[['item','date','balance']])\n",
    "    #       dataWithoutCategory[['item','date','balance']].to_csv('./processed/not_found.csv')\n",
    "    else:\n",
    "        print('no new items')\n",
    "        \n",
    "def resetToCurrentData():\n",
    "    processedData = processData(None, True)  \n",
    "    processedToSave = processedData[processedColumns].sort_values(by='date', ascending=False)\n",
    "    writeToJson(processedToSave)\n",
    "    saveDf(processedToSave, 'processed', 'data', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files should have schema [{'name':string, 'data':pd.DataFrame}, ...]\n",
    "# files = getFiles()\n",
    "# runProcess(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resetToCurrentData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./processed/processed.csv'"
      ]
     },
     "execution_count": 1076,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset data and process from backup\n",
    "from shutil import copyfile\n",
    "copyfile(\"./backup/data.csv\", \"./processed/data.csv\")\n",
    "copyfile(\"./backup/processed.csv\", \"./processed/processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def changeData(hash, subCategory):\n",
    "    df = getFile(\"data\")\n",
    "    df['subCategory'].fillna(\"\",inplace=True)\n",
    "    df.fillna(value=0,inplace=True)\n",
    "    df.loc[dz[\"hash\"] == hash, \"subCategory\"] = subCategory\n",
    "    return df\n",
    "\n",
    "df = changeData(\"bec633716240d8202d8c6e815215fd20cd190bbf\", 'abbas')\n",
    "writeFile(\"data\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kzahir/anaconda3/lib/python3.6/site-packages/plaid/client.py:66: UserWarning: \n",
      "                Development is not intended for production usage.\n",
      "                Swap out url for https://production.plaid.com\n",
      "                via Client.config before switching to production\n",
      "            \n",
      "  ''')\n"
     ]
    }
   ],
   "source": [
    "client = plaid.Client(client_id = keys.PLAID_CLIENT_ID, secret=keys.PLAID_SECRET,\n",
    "                      public_key=keys.PLAID_PUBLIC_KEY, environment=keys.PLAID_ENV, api_version='2019-05-29')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def accountName(name):\n",
    "    result = None\n",
    "    if result == None:\n",
    "        result= accountList[accountList['accountId']==name]['account'].values[0]\n",
    "    if (result == \"Visa Cad\"):\n",
    "        result = \"visa\"\n",
    "    elif (result == 'Personal Line Of Credit'):\n",
    "        result = \"line\"\n",
    "    elif (result==\"Eadvantage Savings Account\"):\n",
    "        result = \"savings\"\n",
    "    elif (result==\"Tfsa Tax Advantage Savings Account\"):\n",
    "        result= \"TFSA\"\n",
    "    elif (result== \"Personal Chequing Account USD\"):\n",
    "        result = \"USD\"\n",
    "    elif (result==\"CIBC Smart Account\"):\n",
    "        result = \"debit\"\n",
    "        \n",
    "    return result\n",
    "\n",
    "def getTrans(start_date, end_date):\n",
    "        \n",
    "    response = client.Transactions.get(keys.access_token,\n",
    "                                       start_date=start_date,\n",
    "                                       end_date=end_date, count=500)\n",
    "    print(\"# Transactions found\" , response['total_transactions'])\n",
    "    \n",
    "    accountList= pd.DataFrame(columns=['account', 'subtype', 'type', 'balanceA', 'balanceC' , 'accountId'])\n",
    "    for account in response['accounts']:\n",
    "        name = account['name']\n",
    "        subtype = account['subtype']\n",
    "        type = account['type']\n",
    "        balanceA= account['balances']['available']\n",
    "        balanceC= account['balances']['current']\n",
    "        accountId= account['account_id']\n",
    "\n",
    "        b = pd.Series({'account':name,'subtype':subtype,'type':type, 'balanceA':balanceA, 'balanceC':balanceC, 'accountId':accountId})\n",
    "        accountList = accountList.append(b, ignore_index=True )\n",
    "        \n",
    "        \n",
    "    transactions = response['transactions']\n",
    "\n",
    "    # Manipulate the count and offset parameters to paginate\n",
    "    # transactions and retrieve all available data\n",
    "    while len(transactions) < response['total_transactions']:\n",
    "        response = client.Transactions.get(keysaccess_token,\n",
    "                                           start_date='2018-01-01',\n",
    "                                           end_date='2019-02-01',\n",
    "                                           offset=len(transactions)\n",
    "                                          )\n",
    "        transactions.extend(response['transactions'])\n",
    "    tx= pd.DataFrame(columns=['date', 'item', 'debit','credit', 'card'])\n",
    "    \n",
    "    for account in transactions:\n",
    "        name = account['name']\n",
    "        date = account['date']\n",
    "        debit = account['amount'] if account['amount'] >= 0 else 0;\n",
    "        credit = -account['amount'] if account['amount'] < 0 else 0;        \n",
    "        accountId= accountName(account['account_id'])\n",
    "\n",
    "        b = pd.Series({'date':date,'item':name,'debit':debit, 'credit':credit, 'card':accountId})\n",
    "        tx = tx.append(b, ignore_index=True )\n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Transactions found 102\n"
     ]
    }
   ],
   "source": [
    "tx = getTrans('2019-01-01', '2019-02-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFiles():\n",
    "    result = []\n",
    "    tx = getTrans('2019-01-01', '2019-02-01')\n",
    "    fileObject={\"name\":None, \"data\":None}\n",
    "    fileObject[\"name\"] = 'plaid'\n",
    "    fileObject[\"data\"] = tx\n",
    "    result.append(fileObject)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tx['item'].str.upper().str.contains('LON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Transactions found 102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item</th>\n",
       "      <th>debit</th>\n",
       "      <th>credit</th>\n",
       "      <th>card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>LONGO'S # 12 MAPLE, ON</td>\n",
       "      <td>105.51</td>\n",
       "      <td>0</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>PREAUTHORIZED DEBIT LN # 1705943330 CIBC LOANS...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>BUY BUY BABY #3703 WOODBRIDGE, ON</td>\n",
       "      <td>47.63</td>\n",
       "      <td>0</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>DOLLARAMA # 245 MAPLE, ON</td>\n",
       "      <td>13.56</td>\n",
       "      <td>0</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>HUSKY SWEET RIVER 6112 CONCORD, ON</td>\n",
       "      <td>37.60</td>\n",
       "      <td>0</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               item   debit  \\\n",
       "0  2019-02-01                             LONGO'S # 12 MAPLE, ON  105.51   \n",
       "1  2019-02-01  PREAUTHORIZED DEBIT LN # 1705943330 CIBC LOANS...    0.04   \n",
       "2  2019-01-31                  BUY BUY BABY #3703 WOODBRIDGE, ON   47.63   \n",
       "3  2019-01-31                          DOLLARAMA # 245 MAPLE, ON   13.56   \n",
       "4  2019-01-31                 HUSKY SWEET RIVER 6112 CONCORD, ON   37.60   \n",
       "\n",
       "  credit   card  \n",
       "0      0   Visa  \n",
       "1      0  Debit  \n",
       "2      0   Visa  \n",
       "3      0   Visa  \n",
       "4      0   Visa  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=getFiles()\n",
    "files[0]['data'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Visa', 'Debit', 'USD']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tx['card'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HASHING UTILITIES\n",
    "# hash the data file\n",
    "# old = pd.read_csv(\"./processed/data.csv\", header=None,names=oldColumns)\n",
    "# old['custom'].fillna(\"\",inplace=True)\n",
    "# old.fillna(value=0,inplace=True)\n",
    "# assert old.dtypes['debit'] == 'float64'\n",
    "# assert old.dtypes['credit'] == 'float64'\n",
    "# old['hash']= hashit(old)\n",
    "# old.to_csv(f'./processed/data.csv', index=False, header=False)\n",
    "\n",
    "# hash the other files\n",
    "# for file in dlFiles:\n",
    "#     old = pd.read_csv(\"./processed/cards/\"+file, header=None,names=oldColumns)\n",
    "#     old['custom'].fillna(\"\",inplace=True)\n",
    "#     old.fillna(value=0,inplace=True)\n",
    "#     assert old.dtypes['debit'] == 'float64'\n",
    "#     assert old.dtypes['credit'] == 'float64'\n",
    "#     old['hash']= hashit(old)\n",
    "#     old.to_csv(f'./processed/{file.split(\".\")[0]}.{file.split(\".\")[1]}', index=False, header=False)\n",
    "\n",
    "# # populate account field in data\n",
    "# oldColumns=['date','item','debit','credit','custom','hash', 'account']\n",
    "\n",
    "# data = pd.read_csv(\"./processed/data.csv\", header=None,names=oldColumns)\n",
    "# for file in dlFiles:\n",
    "#     new = pd.read_csv(\"./processed/\"+file, header=None,names=oldColumns)\n",
    "#     for index, row in new.iterrows():\n",
    "#         if(row['hash'] in data['hash'].values):\n",
    "#             data.loc[data['hash'] == row['hash'],'account']=file.split(\".\")[0]\n",
    "            \n",
    "# data.to_csv(f'./processed/data.csv', index=False, header=False) \n",
    "\n",
    "\n",
    "# # check for duplicate fields\n",
    "\n",
    "# data2 = pd.read_csv(\"./processed/data.csv\", header=None,names=oldColumns)\n",
    "# for index, row in data2.iterrows():\n",
    "#     if(data2[data2['hash']==row['hash']].count()['hash']>2):\n",
    "#         print(row['hash'], row['item'], row['debit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # PROCESS BENCH MARKING\n",
    "# # TESTING TWO FILES\n",
    "# old = pd.read_csv(\"./processed/output-old.csv\", index_col=False)\n",
    "# new = pd.read_csv(\"./processed/processed.csv\", index_col=False)\n",
    "# old.sort_values(by=['date','debit'], inplace=True)\n",
    "# new.sort_values(by=['date','debit'], inplace=True)\n",
    "# old.reset_index( drop=True,inplace=True)\n",
    "# new.reset_index(drop=True,inplace=True)\n",
    "# ineq = []\n",
    "# for i, row in old.iterrows():\n",
    "#     if (row['subCategory'] != new.loc[i]['subCategory']):\n",
    "#         if(row['item']==\"TIGERDIRECT.CA MARKHAM, ON\"):\n",
    "#             pass\n",
    "#         elif('WINNERSHOMESENSE' in row['item']):\n",
    "#             pass\n",
    "#         else:\n",
    "#             pass\n",
    "# #             print(f\"{row['subCategory']}, {new.loc[i]['subCategory']} - {row['balance']} {row['item']}{new.loc[i]['item']}\")\n",
    "            \n",
    "\n",
    "# y = new.groupby('subCategory').sum()['balance']\n",
    "# x = old.groupby('subCategory').sum()['balance']\n",
    "# for i,value in enumerate(x):\n",
    "#     if(value != y[i]):\n",
    "#         print(value, y[i])\n",
    "\n",
    "# # one to one map benchmarking\n",
    "# def try1():    \n",
    "#     def check1to1(x):\n",
    "#         try:\n",
    "#             index = pd.Index(maps['item']).get_loc(x.rstrip())   \n",
    "#             return maps.loc[index]['subCategory']\n",
    "#         except:\n",
    "#             return None\n",
    "\n",
    "#     data['subCategory'] = data['subCategory'].combine_first(data['item'].apply(check1to1))\n",
    "    \n",
    "# def try2():\n",
    "#     data.fillna(\"\", inplace=True)\n",
    "#     subCatArray = []\n",
    "#     # first mapping the 1to1 mappings\n",
    "#     for i, row in data.iterrows():\n",
    "#         if (row['subCategory'] != \"\"):\n",
    "#             subCatArray.append(row['subCategory'])\n",
    "#         else:\n",
    "#             try:\n",
    "#                 index = pd.Index(maps['item']).get_loc(row['item'].rstrip())\n",
    "#                 subCategory = maps.loc[index]['subCategory']\n",
    "#                 subCatArray.append(subCategory)\n",
    "#             except:\n",
    "#                 subCatArray.append(\"\")\n",
    "#     data['subCategory'] = subCatArray\n",
    "# %timeit try1()\n",
    "# %timeit try2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import processData, getFile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processData(None, True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getFile('data')\n",
    "pr = getFile('processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>item</th>\n",
       "      <th>debit</th>\n",
       "      <th>credit</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>hash</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Point of Sale - Interac RETAIL PURCHASE 990001...</td>\n",
       "      <td>89.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bec633716240d8202d8c6e815215fd20cd190bbf</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>Internet Banking E-TRANSFER 100430378413 Hedie...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ea0375ada5fb7a67669f70e2f3be753632c4c7dd</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Point of Sale - Interac RETAIL PURCHASE 000001...</td>\n",
       "      <td>76.54</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a3f2845f8c22d3877b4bda1f301b29e0cfc25627</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Internet Banking INTERNET DEPOSIT 000000253774</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1570.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275e073bde67a0da53e44d941766a077cabcee04</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>Internet Banking INTERNET TRANSFER 000000264971</td>\n",
       "      <td>1364.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>070acc2e7ecfdbdc6c144b67bf717a58adaa7068</td>\n",
       "      <td>debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6643</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Internet Banking POWERSTREAM 000000270043</td>\n",
       "      <td>256.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60abee0623c80b532c5b81fbde472e2f62b83f1a</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6644</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Internet Banking FIDO (SOLUTION INC.) 00000026...</td>\n",
       "      <td>67.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6a6a29d93e91a24e420d75750403be6c2642b2fd</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6645</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Internet Banking FIDO (SOLUTION INC.) 00000026...</td>\n",
       "      <td>28.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de02b30499797d0460b99d4a0a0fb9f2b379916d</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6646</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>Internet Banking ENBRIDGE GAS INC. 000000266212</td>\n",
       "      <td>131.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>674bb10ecb332fc5f021ada58190150b84a625ac</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6647</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>Internet Banking 000000289342</td>\n",
       "      <td>0.00</td>\n",
       "      <td>826.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aa8599800d689658a4673bba822aad0b1adcbc4f</td>\n",
       "      <td>line</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6441 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                               item    debit  \\\n",
       "0     2018-01-03  Point of Sale - Interac RETAIL PURCHASE 990001...    89.04   \n",
       "1     2018-01-03  Internet Banking E-TRANSFER 100430378413 Hedie...   100.00   \n",
       "2     2018-01-02  Point of Sale - Interac RETAIL PURCHASE 000001...    76.54   \n",
       "3     2018-01-02     Internet Banking INTERNET DEPOSIT 000000253774     0.00   \n",
       "4     2018-01-02    Internet Banking INTERNET TRANSFER 000000264971  1364.80   \n",
       "...          ...                                                ...      ...   \n",
       "6643  2019-01-07          Internet Banking POWERSTREAM 000000270043   256.77   \n",
       "6644  2019-01-07  Internet Banking FIDO (SOLUTION INC.) 00000026...    67.80   \n",
       "6645  2019-01-07  Internet Banking FIDO (SOLUTION INC.) 00000026...    28.25   \n",
       "6646  2019-01-07    Internet Banking ENBRIDGE GAS INC. 000000266212   131.24   \n",
       "6647  2019-01-03                      Internet Banking 000000289342     0.00   \n",
       "\n",
       "       credit subCategory                                      hash account  \n",
       "0        0.00         NaN  bec633716240d8202d8c6e815215fd20cd190bbf   debit  \n",
       "1        0.00         NaN  ea0375ada5fb7a67669f70e2f3be753632c4c7dd   debit  \n",
       "2        0.00         NaN  a3f2845f8c22d3877b4bda1f301b29e0cfc25627   debit  \n",
       "3     1570.00         NaN  275e073bde67a0da53e44d941766a077cabcee04   debit  \n",
       "4        0.00         NaN  070acc2e7ecfdbdc6c144b67bf717a58adaa7068   debit  \n",
       "...       ...         ...                                       ...     ...  \n",
       "6643     0.00         NaN  60abee0623c80b532c5b81fbde472e2f62b83f1a    line  \n",
       "6644     0.00         NaN  6a6a29d93e91a24e420d75750403be6c2642b2fd    line  \n",
       "6645     0.00         NaN  de02b30499797d0460b99d4a0a0fb9f2b379916d    line  \n",
       "6646     0.00         NaN  674bb10ecb332fc5f021ada58190150b84a625ac    line  \n",
       "6647   826.74         NaN  aa8599800d689658a4673bba822aad0b1adcbc4f    line  \n",
       "\n",
       "[6441 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['subCategory'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>category</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>debit</th>\n",
       "      <th>credit</th>\n",
       "      <th>balance</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NEW WOK NEW WOK QFF CONCORD, ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>29.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-29.81</td>\n",
       "      <td>visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Playstation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>13.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.49</td>\n",
       "      <td>visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>KID LEE TORONTO, ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>15.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.82</td>\n",
       "      <td>visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>DAAL ROTI MISSISSAUGA, ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>185.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-185.70</td>\n",
       "      <td>visa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               item category subCategory        date  year  \\\n",
       "9   NEW WOK NEW WOK QFF CONCORD, ON      NaN         NaN  2019-03-26  2019   \n",
       "19                      Playstation      NaN         NaN  2019-03-25  2019   \n",
       "57              KID LEE TORONTO, ON      NaN         NaN  2019-03-18  2019   \n",
       "98        DAAL ROTI MISSISSAUGA, ON      NaN         NaN  2019-03-11  2019   \n",
       "\n",
       "    month   debit  credit  balance account  \n",
       "9       3   29.81     0.0   -29.81    visa  \n",
       "19      3   13.49     0.0   -13.49    visa  \n",
       "57      3   15.82     0.0   -15.82    visa  \n",
       "98      3  185.70     0.0  -185.70    visa  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr[pr['item'].str.contains('NEW WOK NEW WOK QFF CONCORD')]\n",
    "pr[pr['subCategory'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
